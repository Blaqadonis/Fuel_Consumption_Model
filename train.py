# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1onPcwhmdw0ITYAsGygAGMjtr3KHKBHzQ
"""

#pip install bentoml

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

from warnings import filterwarnings
filterwarnings('ignore')

data = pd.read_csv('MY2010-2014 Fuel Consumption Ratings 5-cycle.csv.1',encoding="ISO-8859-1")
data1 = data.copy()
data1 = data.iloc[1:,:13]

data1= data1.applymap(lambda s:s.lower().replace(' ', '_') if type(s) == str else s)
data1.columns = [x.lower().replace(' ', '_') for x in data1.columns]
data1.columns = [x.lower().replace(':', '') for x in data1.columns]
data1.columns = [x.lower().replace('*', '') for x in data1.columns]
data1.columns = [x.lower().replace('.', '') for x in data1.columns]


data1 = data1.drop(labels=range(5361,5385), axis=0)

data1["year"] = data1["model"].fillna(0).astype(int)
data1["make"] = data1["make"].astype(object)
data1["model"] = data1["model1"].astype(object)
data1["vehicle_class"] = data1["vehicle_class"].astype(object)
data1["engine_size"] = data1["engine_size"].fillna(0).astype(float)
data1['cylinders'] = data1['cylinders'].fillna(0).astype(int)
data1["transmission"] = data1["transmission"].astype(object)
data1["fuel"] = data1["fuel"].astype(object)
data1["fuel_consumption"] = data1["fuel_consumption"].fillna(0).astype(float)
data1["unnamed_9"] = data1["unnamed_9"].fillna(0).astype(float)
data1["unnamed_10"] = data1["unnamed_10"].fillna(0).astype(float)
data1["unnamed_11"] = data1["unnamed_11"].fillna(0).astype(int) 
data1["co2_emissions_"] = data1["co2_emissions_"].fillna(0).astype(int)

categorical = data1.select_dtypes(include= ["object"]).columns
numerical = data1.select_dtypes(include=np.number).columns

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='most_frequent')
data1[categorical] = imputer.fit_transform(data1[categorical])

data1.drop_duplicates(inplace=True)
data1.reset_index(inplace=True, drop=True)



data1['make_type'] = data1['make'].replace(['bugatti', 'porsche', 'maserati', 'aston_martin', 'lamborghini', 'jaguar','srt'], 'sports')
data1['make_type'] = data1['make_type'].replace(['alfa_romeo', 'audi', 'bmw', 'buick', 'cadillac', 'chrysler', 'dodge', 'gmc','infiniti', 'jeep', 'land_rover', 'lexus', 'mercedes-benz','mini', 'smart', 'volvo'],'premium')
data1['make_type'] = data1['make_type'].replace(['acura', 'bentley', 'lincoln','hummer', 'rolls-royce',  'genesis'], 'luxury')
data1['make_type'] = data1['make_type'].replace(['chevrolet', 'ferrari', 'ford', 'honda', 'hyundai', 'kia', 'mazda', 'mitsubishi', 'nissan','pontiac', 'subaru', 'suzuki', 'toyota', 'volkswagen', 'scion','fiat', 'ram'],'general')
data1.drop(['make'], inplace=True, axis=1)

Q1 = data1[numerical].quantile(0.25)
Q3 = data1[numerical].quantile(0.75)
IQR = Q3 - Q1
outlier = pd.DataFrame((data1[numerical] < (Q1 - 1.5 * IQR)) | (data1[numerical] > (Q3 + 1.5 * IQR)))
data1 = data1[~((data1 < (Q1 - 1.5 * IQR)) |(data1 > (Q3 + 1.5 * IQR))).any(axis=1)]
data1.reset_index(inplace=True, drop=True)

input_numerical = numerical[:-1]
data1[input_numerical] = np.log1p(data1[input_numerical])

y = data1['co2_emissions_']
data1 = data1.drop('co2_emissions_',axis=1)

from sklearn.model_selection import train_test_split
train_data, test_data, y_train_data, y_test = train_test_split(data1, y, test_size = 0.2, random_state=30)
train, val, y_train, y_val = train_test_split(train_data, y_train_data, test_size = 0.25, random_state=11)
train = train.reset_index()
train_data = train_data.reset_index()
test_data = test_data.reset_index()


from sklearn.feature_extraction import DictVectorizer
dict_train = train.to_dict(orient='records')

dv = DictVectorizer(sparse=False)

x_train = dv.fit_transform(dict_train)


xgb_params = {
    'eta': 0.15,
    'max_depth': 3,
    'min_child_weight': 1,

    'objective': 'reg:squarederror',
    'eval_metric': 'rmse',
    'nthread': 8,
    'seed': 1}

import xgboost as xgb
dtrain = xgb.DMatrix(x_train, label=y_train)
model = xgb.train(xgb_params, dtrain,
                  num_boost_round=501, verbose_eval=10)

dict_test = test_data.to_dict(orient='records')
x_test = dv.transform(dict_test)
dtest = xgb.DMatrix(x_test, label=y_test)
y_pred = model.predict(dtest)

import bentoml
bentoml.xgboost.save_model("fuel_consumption_model",model, custom_objects={"DictVectorizer":dv},
signatures={"predict": {"batchable":True,"batch_dim":0,}})